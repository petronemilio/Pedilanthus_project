{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se hace una aproximación de los sistemas Lindenmayer para modelar la diferenciación de las células iniciales cambiales fusiformes.\n",
    "Antes de comenzar es importante introducir nociones báscias acerca de los sistemas Lindemayer así como las condiciones para simular el proceso de desarrollo cambial.\n",
    "Definir un sistema que crezca en una sola dirección para simular una célula cambial que da origen a una célula inicial fusiforme y a otra cambial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import turtle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyRules(lhch):\n",
    "    \"\"\"Apply stochastic rules using random distribution\n",
    "    for values between 0 and 2 to apply rul1 or rule2 or\n",
    "    rule3 \"\"\"\n",
    "    rhstr = \"\"\n",
    "    s = np.random.randint(0,3,1)\n",
    "    if lhch == 'A' and s == 0:\n",
    "        rhstr = 'AF'   # Rule 1\n",
    "    elif lhch == 'A' and s == 1:\n",
    "        rhstr = 'AV' #Rule 2\n",
    "    elif lhch == 'A' and s == 2:\n",
    "        rhstr = 'AP' #Rule 3\n",
    "    elif lhch == 'A':\n",
    "        rhstr = 'B'  # Rule 2\n",
    "    else:\n",
    "        rhstr = lhch    # no rules apply so keep the character\n",
    "\n",
    "    return rhstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processString(oldStr):\n",
    "    newstr = \"\"\n",
    "    for ch in oldStr:\n",
    "        newstr = newstr + applyRules(ch)\n",
    "    return newstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLSystem(numIters,axiom):\n",
    "    startString = axiom\n",
    "    endString = \"\"\n",
    "    for i in range(numIters):\n",
    "        endString = processString(startString)\n",
    "        startString = endString\n",
    "    return endString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_array = np.random.randint(10,150,100)\n",
    "random_files = []\n",
    "for i in lengths_array:\n",
    "    random_files.append(createLSystem(i,'A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AVPPVFPPPVFPVVVPVVPPVFFPVVPVFPVFFPPFVVFPPFPPFVPPVPPPPVFFF'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'B' 'V' 'V' 'F' 'V' 'F']\n"
     ]
    }
   ],
   "source": [
    "#np.random.randint(10,150,100)\n",
    "a = 'ABVVFVF'\n",
    "#print(np.array([list(a) for word in a ]))\n",
    "print(np.array(list(a)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB\n"
     ]
    }
   ],
   "source": [
    "#try new L-system with another approach\n",
    "#cv.dividing = np.array(['A'])\n",
    "def lsystem(axioms, rules, iterations):\n",
    "    #    We iterate through our method required numbers of time.\n",
    "    for _ in range(iterations):\n",
    "        #    Our newly created axioms from this iteration.\n",
    "        newAxioms = ''\n",
    "\n",
    "        #    This is your code, but with renamed variables, for clearer code.\n",
    "        for axiom in axioms:\n",
    "            if axiom in rules:\n",
    "                newAxioms += rules[axiom]\n",
    "            else:\n",
    "                newAxioms += axiom\n",
    "        #    You will need to iterate through your newAxioms next time, so...\n",
    "        #    We transfer newAxioms, to axioms that is being iterated on, in the for loop.\n",
    "        axioms = newAxioms\n",
    "    return axioms\n",
    "\n",
    "rules = { \"A\" : \"B\" , \"B\" : \"A\"}\n",
    "print(lsystem('AB', rules, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BbAbBAbBbBbAbB\n",
      "AbBbBbAbBbBbAbBbAbBbBbAbB\n"
     ]
    }
   ],
   "source": [
    "#determine context sensitivity \n",
    "#try using lists [\"F\",\"P\",\"V\"]\n",
    "rules_try = { \"A\" : \"B\" , \"B\" : \"AbB\" }\n",
    "def iterate(axioms, rules):\n",
    "    new_text = []\n",
    "    for c in list(axioms):\n",
    "        if c in rules:\n",
    "            new_text.append(rules[c])\n",
    "        else:\n",
    "            new_text.append(c)\n",
    "    return ''.join(new_text)\n",
    "def lsystem(axioms, rules, iteration):\n",
    "    new_text = []\n",
    "    x = axioms\n",
    "    for i in range(iteration):\n",
    "        x=iterate(x, rules)\n",
    "        #new_text.append(x)\n",
    "    return ''.join(x)\n",
    "print(lsystem('AB',rules_try,3))\n",
    "print(lsystem('B',rules_try,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABFFFFFFFFFFFFFFFPFFPFPFFFPFFFPPFFFFFFFFFPFFFFPFFPFPFFFPFFFFFFFPFFFFFFFFFFFFPFPFFFFFFFFFPFFFFPFFFPFFFFFPFFPFFFFFFFFFPFFFFFFPPFPFFPFPFFFPFFFFFFFFFFFPFFFFPFFFFFFFFFFFFFFFPFFFFPFFPFFFPFFPFFFFFFFFFFPFFFFFFFPFFFFFFFFFFFFFPFFFFFFFPFFPFFFFPFFPFFFPFFFPFFFFPFFFFFPVPFPFFFFFPPFFFFFPFFFFFFFPFFFFPFFFFFFFFFPFFFFFFFPFFPFPFPVV\n"
     ]
    }
   ],
   "source": [
    "#determine context sensitivity \n",
    "#try using lists [\"F\",\"P\",\"V\"]\n",
    "rules_ctsens = { \"A\" : \"AB\" , \"B\" : [\"V\",\"F\",\"P\"]} #Rules that generate cv derivatives\n",
    "def iterate(axioms, rules):\n",
    "    new_text = []\n",
    "    parsero = list(axioms)\n",
    "    parsero.append('')\n",
    "    for i, item in enumerate(parsero):\n",
    "        if item == '':\n",
    "            pass\n",
    "        #If string is just AB it will generate V,F or P with equal probability\n",
    "        elif item in rules and parsero[i+1]=='':\n",
    "            s = np.random.randint(0,3,1)\n",
    "            if s == 0:\n",
    "                new_text.append(rules[item][0])\n",
    "            elif s == 1:\n",
    "                new_text.append(rules[item][1])\n",
    "            else:\n",
    "                new_text.append(rules[item][2])\n",
    "        #Contexte sensitivity. If V is the last derivative produced \n",
    "        # probabilities are different\n",
    "        elif item in rules and parsero[i+1]=='V':\n",
    "            s = np.random.uniform(low=0, high=1, size=None)\n",
    "            if s < 0.44:\n",
    "                new_text.append(rules[item][0])\n",
    "            elif 0.44 <= s < 0.9:\n",
    "                new_text.append(rules[item][2])  \n",
    "            else:    \n",
    "                new_text.append(rules[item][1])     \n",
    "        #Contexte sensitivity. If F is the last derivative produced \n",
    "        # probabilities are different\n",
    "        elif item in rules and parsero[i+1]== 'F':\n",
    "            s = np.random.uniform(low=0, high=1, size=None)\n",
    "            if s < 0.001:\n",
    "                new_text.append(rules[item][0])\n",
    "            elif 0.001 <= s < 0.784 :\n",
    "                new_text.append(rules[item][1])  \n",
    "            else:    \n",
    "                new_text.append(rules[item][2])\n",
    "        #Contexte sensitivity. If P is the last derivative produced \n",
    "        # probabilities are different        \n",
    "        elif item in rules and parsero[i+1]== 'P':\n",
    "            s = np.random.uniform(low=0, high=1, size=None)\n",
    "            if s < 0.08 :\n",
    "                new_text.append(rules[item][2])\n",
    "            elif 0.08 <= s < 0.12 :\n",
    "                new_text.append(rules[item][0])  \n",
    "            else:    \n",
    "                new_text.append(rules[item][1])  \n",
    "                \n",
    "        elif item in rules:\n",
    "            new_text.append(rules[item])\n",
    "        \n",
    "        else:\n",
    "            new_text.append(item)\n",
    "    return ''.join(new_text)\n",
    "\n",
    "def lsystem(axioms, rules, iteration):\n",
    "    x = axioms\n",
    "    for i in range(iteration):\n",
    "        x=iterate(x, rules)\n",
    "        #new_text.append(x)\n",
    "    return ''.join(x)\n",
    "print(lsystem('AB',rules_try,310))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7032991310066622\n",
      "0.3280949913118\n",
      "0.2881175144914768\n",
      "0.7734235697928693\n",
      "0.4254280391655748\n",
      "0.6604345631681996\n",
      "0.49668483185904666\n",
      "0.7353093118560768\n",
      "0.19541782067136437\n",
      "0.6357823672980727\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(np.random.uniform(low=0, high=1, size=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of the stochastic context-sensitive L-system\n",
    "\n",
    "#### Alphabet:\n",
    "\n",
    "- Ci = cambial inicial\n",
    "- Cd = cambial diferenciable\n",
    "- V = vaso\n",
    "- F = fibra\n",
    "- P = parénquima\n",
    "\n",
    "#### Production rules\n",
    "\n",
    "|Axiom | w: $$C_i$$ |\n",
    "| ---- | ----------- |\n",
    "|Productions:|\n",
    "| $$p_1$$ | $C_i \\rightarrow C_i C_d$ |\n",
    "| $$p_2$$ | $C_i < C_d \\xrightarrow{\\text{0.33}} F$\n",
    "| $$p_3$$ | $C_i < C_d \\xrightarrow{\\text{0.33}}  P$\n",
    "| $$p_4$$ | $C_i < C_d\\xrightarrow{\\text{0.33}} V$\n",
    "| $$p_5$$ | $C_i < C_d > F \\xrightarrow{\\text{p}} F$\n",
    "| $$p_6$$ | $C_i < C_d > F \\xrightarrow{\\text{p}} P$\n",
    "| $$p_7$$ | $C_i < C_d > F \\xrightarrow{\\text{p}} V$\n",
    "| $$p_8$$ | $C_i < C_d > P \\xrightarrow{\\text{p}} F$\n",
    "| $$p_9$$ | $C_i < C_d > P \\xrightarrow{\\text{p}} P$\n",
    "| $$p_{10}$$ | $C_i < C_d > P \\xrightarrow{\\text{p}} V$\n",
    "| $$p_{11}$$ | $C_i < C_d > V \\xrightarrow{\\text{p}} F$\n",
    "| $$p_{12}$$ | $C_i < C_d > V \\xrightarrow{\\text{p}} P$\n",
    "| $$p_{13}$$ | $C_i < C_d > V \\xrightarrow{\\text{p}} V$\n",
    "\n",
    "Probabilities depend on the transition probability matrix determined empiricaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to put the probabilities in the \n",
    "\n",
    "#F-V (12, 0.0010682809578919255)\n",
    "#F-P (814, 0.07246505831033562)\n",
    "#V-V (31, 0.0027597258078874746)\n",
    "#V-P (75, 0.006676755986824535)\n",
    "#V-F (44, 0.003917030178937061)\n",
    "#P-P (237, 0.02109854891836553)\n",
    "#P-V (115, 0.010237692513130954)\n",
    "#P-F (786, 0.06997240274192112)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    }
   ],
   "source": [
    "#Make a dictionary with the production rules\n",
    "production_rules = {'C': ['D'], 'D': ['F','P','V']}\n",
    "axiom = 'C'\n",
    "for i in range(10):\n",
    "    s = np.random.randint(0,3,1)\n",
    "    for ch in axiom:\n",
    "        if ch in production_rules.keys() == 'C':\n",
    "            axiom = axiom + production_rules['C'][0]\n",
    "        elif ch in production_rules.keys() == 'D' and s == 0:\n",
    "            axiom = axiom + production_rules['D'][0]\n",
    "        elif ch in production_rules.keys() == 'D' and s == 1:\n",
    "            axiom = axiom + production_rules['D'][1]    \n",
    "print(axiom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word counting\n",
    "Using the random_files array to count frequencies and stablish the vocabulary with a defined k-mer length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get words regresa un diccionario con las palabras y los conteos.\n",
    "#Se puede aprovechar para usarlo con multiples conteos\n",
    "def get_words(file, x):\n",
    "    \"\"\"Determine the number of different words in \n",
    "    a given string. It needs two arguments: \n",
    "    1)a given string\n",
    "    2) the length of the k-mer to determine\"\"\"\n",
    "    #Create empty set to add the different words\n",
    "    words = {}\n",
    "    #go trhough the string:\n",
    "    for z in range(0,len(file)):\n",
    "        word = file[z:z+x]\n",
    "        if len(word) == x:\n",
    "            words[word] = words.get(word,0)\n",
    "            words[word] = words[word] +1\n",
    "        else:\n",
    "            pass\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_words(array):\n",
    "    \"\"\"Determine the number of different words in \n",
    "    a given array. It uses the get_words function\"\"\"\n",
    "    #Create empty set to add the different words\n",
    "    words = {}\n",
    "    #iterate trhough the files:\n",
    "    for i in array:\n",
    "        x = get_words(i, 4) \n",
    "        for keys,values in x.items():\n",
    "            words[keys] = words.get(keys,0)\n",
    "            words[keys] = words[keys] + values \n",
    "        #aquí debería de venir una forma de agregar cada \n",
    "        #diccionario de x a words\n",
    "    return(words)\n",
    "#Se cambió la función..... en lugar..\n",
    "#Parece que las dos funciones funcionan.#Utilizarlas con los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AVVP': 1, 'VVPF': 3, 'VPFF': 2, 'PFFF': 1, 'FFFV': 1, 'FFVV': 2, 'FVVV': 1, 'VVVF': 1, 'VVFP': 1, 'VFPP': 1, 'FPPV': 1, 'PPVV': 2, 'PVVP': 3, 'PFFV': 1, 'FVVP': 1, 'VPFP': 1, 'PFPV': 1, 'FPVV': 2, 'VVPP': 1, 'VPPV': 1, 'PVVF': 1, 'VVFF': 1, 'VFFP': 1, 'FFPV': 1, 'VVPV': 1, 'VPVF': 1}\n",
      "{'APPV': 1, 'PPVF': 1, 'PVFP': 1, 'VFPF': 1, 'FPFV': 1, 'PFVP': 1, 'FVPP': 2, 'VPPP': 1, 'PPPP': 1, 'PPPF': 1, 'PPFF': 2, 'PFFV': 2, 'FFVP': 1, 'VPPF': 1, 'FFVV': 1, 'FVVF': 1, 'VVFV': 1, 'VFVP': 1, 'FVPV': 1, 'VPVV': 1}\n"
     ]
    }
   ],
   "source": [
    "print(get_words(random_files[1],4))\n",
    "print(get_words(random_files[2],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_all_words(random_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las funciones ya funcionan. Ahora se tiene cargar un de pedilanthus y convertirlo en una lista de strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/P_bracteatus/845_edited_cells.txt', 'r') as f: # 'r' stands for reading\n",
    "    bractetus_845 = f.readlines()\n",
    "bracteatus_845 = [x.strip() for x in bractetus_845] \n",
    "with open('../Data/P_calcaratus/896_edited_cells.txt', 'r') as f: # 'r' stands for reading\n",
    "    calcaratus_896 = f.readlines()\n",
    "calcaratus_896 = [x.strip() for x in calcaratus_896] \n",
    "calcaratus_896 = [x.upper() for x in calcaratus_896]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bracteatus_845_words = get_all_words(bracteatus_845)\n",
    "calcaratus_896_words = get_all_words(calcaratus_896)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FFFF': 7521, 'FFFP': 668, 'FFPV': 87, 'FPVP': 46, 'PVPP': 3, 'VPPP': 2, 'PPPF': 47, 'PPFF': 114, 'PFFF': 654, 'FFPF': 516, 'FPFF': 526, 'FFPP': 124, 'FPPP': 50, 'FPFP': 54, 'PFPF': 59, 'FPPF': 71, 'RRRR': 1715, 'PVPF': 49, 'VPFF': 58, 'FPVV': 19, 'PVVF': 6, 'VVFF': 9, 'VFFF': 39, 'PFFP': 51, 'PPFP': 10, 'RRRF': 15, 'RRFF': 10, 'RFFF': 7, 'FPVF': 22, 'PVFF': 30, 'FPPV': 11, 'PPVP': 10, 'FPFV': 1, 'PFVF': 1, 'FVFF': 3, 'RRRP': 2, 'RRPP': 2, 'RPPF': 1, 'PPPP': 29, 'VPFP': 7, 'RRFP': 5, 'RFPF': 3, 'PVPV': 2, 'VPVF': 3, 'PFPV': 1, 'PVVP': 9, 'VVPF': 13, 'PPVF': 4, 'PFPP': 10, 'PVVV': 5, 'VVVP': 4, 'PPPV': 3, 'VPPF': 1, 'RFPV': 1, 'VVPP': 1, 'VVVF': 2, 'FFFV': 11, 'FFVP': 4, 'FVPV': 1, 'VFFP': 3, 'RFPP': 1, 'FFVV': 4, 'FVVV': 1, 'VVPV': 1, 'RFFP': 3, 'FVVF': 1, 'FFVF': 2, 'VFFV': 1, 'FVPF': 3, 'RPPV': 1, 'FVVP': 2, 'VPPV': 1, 'PPVV': 2, 'PVFP': 1, 'VFPV': 1}\n",
      "{'FFFP': 1023, 'FFPF': 1202, 'FPFF': 1202, 'PFFF': 1025, 'FFFF': 5134, 'PFFP': 233, 'FPFP': 246, 'PFPF': 245, 'FFPP': 40, 'FPPF': 25, 'PPFF': 37, 'RRRR': 3043, 'RRRF': 34, 'RRFF': 26, 'RFFF': 15, 'FFFR': 5, 'FFRR': 8, 'FRRR': 12, 'RFFR': 5, 'FPPP': 21, 'PPPF': 21, 'PPFP': 14, 'RFFP': 7, 'PPPP': 45, 'FFPV': 23, 'FPVF': 7, 'PVFF': 9, 'VFFF': 14, 'FPVP': 12, 'PVPF': 7, 'VPFF': 17, 'VVVV': 13, 'VVVP': 14, 'VVPF': 14, 'VVPV': 3, 'VPVV': 11, 'PVVF': 5, 'VVFP': 1, 'VFPF': 2, 'PVFP': 1, 'RRFR': 4, 'RFRR': 4, 'RRFP': 4, 'RFPP': 1, 'FPVV': 12, 'VVFF': 9, 'VFFP': 5, 'PVVV': 13, 'PVPV': 12, 'FPPV': 5, 'PPVP': 4, 'VPVP': 4, 'VPFP': 4, 'PFPP': 12, 'PPFV': 1, 'PFVF': 1, 'FVFF': 1, 'PFPV': 9, 'PVVP': 5, 'PVPP': 1, 'VPPP': 1, 'PPPV': 2, 'PPVF': 2, 'FFRF': 1, 'FRFR': 1, 'RFRF': 1, 'FRFF': 1, 'VVPP': 4, 'VPPF': 4, 'RRRP': 1, 'RRPF': 1, 'RPFF': 1, 'FFFV': 6, 'FFVF': 1, 'FFVP': 2, 'FVPV': 2, 'VVVF': 5, 'FFVV': 2, 'FVVV': 2, 'RFPF': 3, 'PFFR': 1, 'FFRO': 1, 'FROT': 1, 'ROTA': 2, 'OTAS': 2, 'TASF': 2, 'ASFF': 2, 'SFFF': 2, 'FFPR': 1, 'FPRO': 1, 'PROT': 1, 'VPVF': 2, 'PPVV': 1}\n"
     ]
    }
   ],
   "source": [
    "print(bracteatus_845_words)\n",
    "print(calcaratus_896_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euc_dist(x, y):\n",
    "    \"\"\"Function to calculate the euclidian distance between\n",
    "    two different dictionaries with word counts.\"\"\"\n",
    "    ss = 0 #sum of squares between words\n",
    "    for key in x:\n",
    "        if key in y:\n",
    "            ss += (x[key] - y[key])**2\n",
    "        else:\n",
    "            ss += (x[key])**2\n",
    "    for key in y:\n",
    "        if key not in x:\n",
    "            ss += (y[key])**2\n",
    "    distance = math.sqrt(ss)\n",
    "    \n",
    "    return distance\n",
    "#Como sumar las palabras que no aparecen                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1992.0366462492602"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euc_dist(x,bracteatus_845_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2964.115045000784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ASFF',\n",
       " 'FFFR',\n",
       " 'FFPR',\n",
       " 'FFRF',\n",
       " 'FFRO',\n",
       " 'FFRR',\n",
       " 'FPFV',\n",
       " 'FPRO',\n",
       " 'FRFF',\n",
       " 'FRFR',\n",
       " 'FROT',\n",
       " 'FRRR',\n",
       " 'FVPF',\n",
       " 'FVVF',\n",
       " 'FVVP',\n",
       " 'OTAS',\n",
       " 'PFFR',\n",
       " 'PPFV',\n",
       " 'PROT',\n",
       " 'RFFR',\n",
       " 'RFPV',\n",
       " 'RFRF',\n",
       " 'RFRR',\n",
       " 'ROTA',\n",
       " 'RPFF',\n",
       " 'RPPF',\n",
       " 'RPPV',\n",
       " 'RRFR',\n",
       " 'RRPF',\n",
       " 'RRPP',\n",
       " 'SFFF',\n",
       " 'TASF',\n",
       " 'VFFV',\n",
       " 'VFPF',\n",
       " 'VFPV',\n",
       " 'VPPV',\n",
       " 'VPVP',\n",
       " 'VPVV',\n",
       " 'VVFP',\n",
       " 'VVVV'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(euc_dist(calcaratus_896_words,bracteatus_845_words))\n",
    "calck = set(calcaratus_896_words.keys())\n",
    "brack = set(bracteatus_845_words.keys())\n",
    "calck.symmetric_difference(brack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {'FFFF': 7521, 'FFFP': 668, 'FFPV': 87, \n",
    "     'FPVP': 46, 'PVPP': 3, 'VPPP': 2, 'PPPF': 47}\n",
    "y = {'FFFF': 133, 'PFFP': 668, 'FFPV': 2, \n",
    "     'FPVP': 46, 'PVPP': 3, 'VPPP': 233, 'PVPF': 47}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xkeys = set(x.keys())\n",
    "ykeys = set(y.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FFFP', 'PFFP', 'PPPF', 'PVPF'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xkeys.symmetric_difference(ykeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = {'C':[0,1,2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z['C'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'AA', 'AB', 'B', 'C', 'D', 'E', 'ABC', 'DA', 'BC', 'AAA', 'BCD', 'EE', 'EEE', 'EC', 'BB', 'BBB', 'BD', 'DAA']\n"
     ]
    }
   ],
   "source": [
    "input_str = 'AAAABBCDEABCDABCAAABCDEEEEEECBBBBBBDDAAE'\n",
    "\n",
    "keys_dict = {}\n",
    "\n",
    "ind = 0\n",
    "inc = 1\n",
    "while True:\n",
    "    if not (len(input_str) >= ind+inc):\n",
    "        break\n",
    "    sub_str = input_str[ind:ind + inc]\n",
    "    #print(sub_str,ind,inc)\n",
    "    if sub_str in keys_dict:\n",
    "        inc += 1\n",
    "    else:\n",
    "        keys_dict[sub_str] = 0\n",
    "        ind += inc\n",
    "        inc = 1\n",
    "        # print 'Adding %s' %sub_str\n",
    "\n",
    "print(list(keys_dict)) #¿cómo es que no hace palabras de más de tres letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data/P_bracteatus/845_edited_cells.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-dff8c1b775fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Data/P_bracteatus/845_edited_cells.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 'r' stands for reading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mbractetus_845\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbracteatus_845\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbractetus_845\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/P_bracteatus/845_edited_cells.txt'"
     ]
    }
   ],
   "source": [
    "with open('../Data/', 'r') as f: # 'r' stands for reading\n",
    "    bractetus_845 = f.readlines()\n",
    "bracteatus_845 = [x.strip() for x in bractetus_845] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
